{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab79052f",
   "metadata": {},
   "source": [
    "# Stream Data Loading - Good vs Bad Examples\n",
    "\n",
    "This notebook demonstrates **meaningful** vs **trivial** implementations of stream-based data loading in C#.\n",
    "\n",
    "## What Are Streams?\n",
    "\n",
    "Streams provide a common interface for reading and writing data from various sources:\n",
    "- **File streams** - Reading/writing files\n",
    "- **Network streams** - HTTP, TCP, web services\n",
    "- **Memory streams** - In-memory data processing\n",
    "- **Compressed streams** - ZIP, GZIP data\n",
    "- **Crypto streams** - Encrypted data\n",
    "\n",
    "### Key Benefits of Streams:\n",
    "1. **Memory efficiency** - Process large files without loading everything into memory\n",
    "2. **Resource management** - Proper disposal with `using` statements\n",
    "3. **Flexibility** - Same interface for different data sources\n",
    "4. **Async support** - Non-blocking operations for better performance\n",
    "5. **Buffering** - Optimized read/write operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c16918",
   "metadata": {},
   "source": [
    "### ✅ Good Examples - Meaningful Stream Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57834ea0",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// ✅ GOOD: File reading with proper resource management\n",
    "public class FileDataLoader\n",
    "{\n",
    "    // Reading CSV data with streams\n",
    "    public static async Task<List<Dictionary<string, string>>> LoadCsvDataAsync(string filePath)\n",
    "    {\n",
    "        var records = new List<Dictionary<string, string>>();\n",
    "        \n",
    "        using var fileStream = new FileStream(filePath, FileMode.Open, FileAccess.Read);\n",
    "        using var reader = new StreamReader(fileStream);\n",
    "        \n",
    "        // Read header\n",
    "        var headerLine = await reader.ReadLineAsync();\n",
    "        if (headerLine == null) return records;\n",
    "        \n",
    "        var headers = headerLine.Split(',').Select(h => h.Trim()).ToArray();\n",
    "        \n",
    "        // Read data rows\n",
    "        string line;\n",
    "        while ((line = await reader.ReadLineAsync()) != null)\n",
    "        {\n",
    "            var values = line.Split(',').Select(v => v.Trim()).ToArray();\n",
    "            var record = new Dictionary<string, string>();\n",
    "            \n",
    "            for (int i = 0; i < Math.Min(headers.Length, values.Length); i++)\n",
    "            {\n",
    "                record[headers[i]] = values[i];\n",
    "            }\n",
    "            \n",
    "            records.Add(record);\n",
    "        }\n",
    "        \n",
    "        return records;\n",
    "    }\n",
    "    \n",
    "    // Reading large files line by line to avoid memory issues\n",
    "    public static async IAsyncEnumerable<string> ReadLargeFileAsync(string filePath)\n",
    "    {\n",
    "        using var fileStream = new FileStream(filePath, FileMode.Open, FileAccess.Read);\n",
    "        using var reader = new StreamReader(fileStream);\n",
    "        \n",
    "        string line;\n",
    "        while ((line = await reader.ReadLineAsync()) != null)\n",
    "        {\n",
    "            yield return line;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Writing data with buffering\n",
    "    public static async Task WriteDataAsync(string filePath, IEnumerable<string> data)\n",
    "    {\n",
    "        using var fileStream = new FileStream(filePath, FileMode.Create, FileAccess.Write);\n",
    "        using var writer = new StreamWriter(fileStream);\n",
    "        \n",
    "        foreach (var item in data)\n",
    "        {\n",
    "            await writer.WriteLineAsync(item);\n",
    "        }\n",
    "        \n",
    "        await writer.FlushAsync();\n",
    "    }\n",
    "    \n",
    "    // Copy file with progress reporting\n",
    "    public static async Task CopyFileWithProgressAsync(string sourcePath, string destinationPath, \n",
    "                                                      IProgress<double> progress = null)\n",
    "    {\n",
    "        const int bufferSize = 4096;\n",
    "        var buffer = new byte[bufferSize];\n",
    "        \n",
    "        using var sourceStream = new FileStream(sourcePath, FileMode.Open, FileAccess.Read);\n",
    "        using var destinationStream = new FileStream(destinationPath, FileMode.Create, FileAccess.Write);\n",
    "        \n",
    "        long totalBytes = sourceStream.Length;\n",
    "        long totalBytesRead = 0;\n",
    "        \n",
    "        int bytesRead;\n",
    "        while ((bytesRead = await sourceStream.ReadAsync(buffer, 0, buffer.Length)) > 0)\n",
    "        {\n",
    "            await destinationStream.WriteAsync(buffer, 0, bytesRead);\n",
    "            totalBytesRead += bytesRead;\n",
    "            \n",
    "            // Report progress\n",
    "            progress?.Report((double)totalBytesRead / totalBytes * 100);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2380b",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// ✅ GOOD: HTTP data loading with streams\n",
    "public class HttpDataLoader\n",
    "{\n",
    "    private static readonly HttpClient _httpClient = new HttpClient();\n",
    "    \n",
    "    // Download large files without loading into memory\n",
    "    public static async Task DownloadFileAsync(string url, string destinationPath, \n",
    "                                              IProgress<double> progress = null)\n",
    "    {\n",
    "        using var response = await _httpClient.GetAsync(url, HttpCompletionOption.ResponseHeadersRead);\n",
    "        response.EnsureSuccessStatusCode();\n",
    "        \n",
    "        var totalBytes = response.Content.Headers.ContentLength ?? 0;\n",
    "        \n",
    "        using var contentStream = await response.Content.ReadAsStreamAsync();\n",
    "        using var fileStream = new FileStream(destinationPath, FileMode.Create, FileAccess.Write);\n",
    "        \n",
    "        var buffer = new byte[4096];\n",
    "        long totalBytesRead = 0;\n",
    "        int bytesRead;\n",
    "        \n",
    "        while ((bytesRead = await contentStream.ReadAsync(buffer, 0, buffer.Length)) > 0)\n",
    "        {\n",
    "            await fileStream.WriteAsync(buffer, 0, bytesRead);\n",
    "            totalBytesRead += bytesRead;\n",
    "            \n",
    "            if (totalBytes > 0)\n",
    "            {\n",
    "                progress?.Report((double)totalBytesRead / totalBytes * 100);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Stream JSON data from API\n",
    "    public static async Task<T> LoadJsonAsync<T>(string url)\n",
    "    {\n",
    "        using var response = await _httpClient.GetAsync(url);\n",
    "        response.EnsureSuccessStatusCode();\n",
    "        \n",
    "        using var stream = await response.Content.ReadAsStreamAsync();\n",
    "        return await System.Text.Json.JsonSerializer.DeserializeAsync<T>(stream);\n",
    "    }\n",
    "    \n",
    "    // Stream large JSON arrays item by item\n",
    "    public static async IAsyncEnumerable<T> StreamJsonArrayAsync<T>(string url)\n",
    "    {\n",
    "        using var response = await _httpClient.GetAsync(url, HttpCompletionOption.ResponseHeadersRead);\n",
    "        response.EnsureSuccessStatusCode();\n",
    "        \n",
    "        using var stream = await response.Content.ReadAsStreamAsync();\n",
    "        using var reader = new StreamReader(stream);\n",
    "        \n",
    "        var line = await reader.ReadLineAsync(); // Skip opening bracket\n",
    "        \n",
    "        while ((line = await reader.ReadLineAsync()) != null)\n",
    "        {\n",
    "            if (line.Trim() == \"]\" || line.Trim() == \"}\") break;\n",
    "            \n",
    "            var cleanLine = line.TrimEnd(',');\n",
    "            if (!string.IsNullOrWhiteSpace(cleanLine))\n",
    "            {\n",
    "                yield return System.Text.Json.JsonSerializer.Deserialize<T>(cleanLine);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Upload data with streaming\n",
    "    public static async Task<HttpResponseMessage> UploadStreamAsync(string url, Stream dataStream, \n",
    "                                                                   string contentType = \"application/octet-stream\")\n",
    "    {\n",
    "        using var content = new StreamContent(dataStream);\n",
    "        content.Headers.ContentType = new System.Net.Http.Headers.MediaTypeHeaderValue(contentType);\n",
    "        \n",
    "        return await _httpClient.PostAsync(url, content);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc1193",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// ✅ GOOD: Memory streams for data processing\n",
    "public class MemoryStreamProcessor\n",
    "{\n",
    "    // Convert object to bytes and back\n",
    "    public static byte[] SerializeToBytes<T>(T obj)\n",
    "    {\n",
    "        using var memoryStream = new MemoryStream();\n",
    "        using var writer = new StreamWriter(memoryStream);\n",
    "        \n",
    "        var json = System.Text.Json.JsonSerializer.Serialize(obj);\n",
    "        writer.Write(json);\n",
    "        writer.Flush();\n",
    "        \n",
    "        return memoryStream.ToArray();\n",
    "    }\n",
    "    \n",
    "    public static T DeserializeFromBytes<T>(byte[] data)\n",
    "    {\n",
    "        using var memoryStream = new MemoryStream(data);\n",
    "        using var reader = new StreamReader(memoryStream);\n",
    "        \n",
    "        var json = reader.ReadToEnd();\n",
    "        return System.Text.Json.JsonSerializer.Deserialize<T>(json);\n",
    "    }\n",
    "    \n",
    "    // Process data in chunks\n",
    "    public static async Task<List<T>> ProcessDataInChunksAsync<T>(IEnumerable<T> data, \n",
    "                                                                 Func<List<T>, Task<List<T>>> processor, \n",
    "                                                                 int chunkSize = 1000)\n",
    "    {\n",
    "        var results = new List<T>();\n",
    "        \n",
    "        using var memoryStream = new MemoryStream();\n",
    "        var chunk = new List<T>();\n",
    "        \n",
    "        foreach (var item in data)\n",
    "        {\n",
    "            chunk.Add(item);\n",
    "            \n",
    "            if (chunk.Count >= chunkSize)\n",
    "            {\n",
    "                var processedChunk = await processor(chunk);\n",
    "                results.AddRange(processedChunk);\n",
    "                chunk.Clear();\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // Process remaining items\n",
    "        if (chunk.Count > 0)\n",
    "        {\n",
    "            var processedChunk = await processor(chunk);\n",
    "            results.AddRange(processedChunk);\n",
    "        }\n",
    "        \n",
    "        return results;\n",
    "    }\n",
    "    \n",
    "    // Create in-memory data for testing\n",
    "    public static Stream CreateTestDataStream(int numberOfRecords)\n",
    "    {\n",
    "        var memoryStream = new MemoryStream();\n",
    "        var writer = new StreamWriter(memoryStream, leaveOpen: true);\n",
    "        \n",
    "        // Write CSV header\n",
    "        writer.WriteLine(\"Id,Name,Email,CreatedDate\");\n",
    "        \n",
    "        // Write test data\n",
    "        for (int i = 1; i <= numberOfRecords; i++)\n",
    "        {\n",
    "            writer.WriteLine($\"{i},User{i},user{i}@example.com,{DateTime.Now.AddDays(-i):yyyy-MM-dd}\");\n",
    "        }\n",
    "        \n",
    "        writer.Flush();\n",
    "        memoryStream.Position = 0; // Reset to beginning\n",
    "        \n",
    "        return memoryStream;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b2716",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// ✅ GOOD: Compressed stream handling\n",
    "using System.IO.Compression;\n",
    "\n",
    "public class CompressionProcessor\n",
    "{\n",
    "    // Read data from GZIP compressed file\n",
    "    public static async Task<string> ReadGzipFileAsync(string gzipFilePath)\n",
    "    {\n",
    "        using var fileStream = new FileStream(gzipFilePath, FileMode.Open, FileAccess.Read);\n",
    "        using var gzipStream = new GZipStream(fileStream, CompressionMode.Decompress);\n",
    "        using var reader = new StreamReader(gzipStream);\n",
    "        \n",
    "        return await reader.ReadToEndAsync();\n",
    "    }\n",
    "    \n",
    "    // Write data to GZIP compressed file\n",
    "    public static async Task WriteGzipFileAsync(string filePath, string content)\n",
    "    {\n",
    "        using var fileStream = new FileStream(filePath, FileMode.Create, FileAccess.Write);\n",
    "        using var gzipStream = new GZipStream(fileStream, CompressionLevel.Optimal);\n",
    "        using var writer = new StreamWriter(gzipStream);\n",
    "        \n",
    "        await writer.WriteAsync(content);\n",
    "        await writer.FlushAsync();\n",
    "    }\n",
    "    \n",
    "    // Process ZIP archive entries\n",
    "    public static async Task<Dictionary<string, string>> ReadZipArchiveAsync(string zipFilePath)\n",
    "    {\n",
    "        var files = new Dictionary<string, string>();\n",
    "        \n",
    "        using var fileStream = new FileStream(zipFilePath, FileMode.Open, FileAccess.Read);\n",
    "        using var archive = new ZipArchive(fileStream, ZipArchiveMode.Read);\n",
    "        \n",
    "        foreach (var entry in archive.Entries)\n",
    "        {\n",
    "            if (!entry.Name.EndsWith(\".txt\", StringComparison.OrdinalIgnoreCase))\n",
    "                continue;\n",
    "                \n",
    "            using var entryStream = entry.Open();\n",
    "            using var reader = new StreamReader(entryStream);\n",
    "            \n",
    "            var content = await reader.ReadToEndAsync();\n",
    "            files[entry.Name] = content;\n",
    "        }\n",
    "        \n",
    "        return files;\n",
    "    }\n",
    "    \n",
    "    // Create ZIP archive from multiple streams\n",
    "    public static async Task CreateZipArchiveAsync(string zipFilePath, \n",
    "                                                   Dictionary<string, Stream> files)\n",
    "    {\n",
    "        using var fileStream = new FileStream(zipFilePath, FileMode.Create, FileAccess.Write);\n",
    "        using var archive = new ZipArchive(fileStream, ZipArchiveMode.Create);\n",
    "        \n",
    "        foreach (var file in files)\n",
    "        {\n",
    "            var entry = archive.CreateEntry(file.Key);\n",
    "            \n",
    "            using var entryStream = entry.Open();\n",
    "            file.Value.Position = 0; // Reset stream position\n",
    "            await file.Value.CopyToAsync(entryStream);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f3af73",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// ✅ GOOD USAGE: Demonstrate proper stream usage with real scenarios\n",
    "\n",
    "// Example 1: Processing large CSV file without loading all into memory\n",
    "async Task ProcessLargeCsvFile()\n",
    "{\n",
    "    var testDataStream = MemoryStreamProcessor.CreateTestDataStream(1000);\n",
    "    \n",
    "    // Simulate saving to a file\n",
    "    var tempFile = Path.GetTempFileName();\n",
    "    \n",
    "    try\n",
    "    {\n",
    "        // Save test data to file\n",
    "        using (var fileStream = new FileStream(tempFile, FileMode.Create, FileAccess.Write))\n",
    "        {\n",
    "            await testDataStream.CopyToAsync(fileStream);\n",
    "        }\n",
    "        \n",
    "        // Now read it back using streams\n",
    "        var records = await FileDataLoader.LoadCsvDataAsync(tempFile);\n",
    "        Console.WriteLine($\"Loaded {records.Count} records from CSV\");\n",
    "        \n",
    "        // Display first few records\n",
    "        foreach (var record in records.Take(3))\n",
    "        {\n",
    "            Console.WriteLine($\"ID: {record[\"Id\"]}, Name: {record[\"Name\"]}, Email: {record[\"Email\"]}\");\n",
    "        }\n",
    "    }\n",
    "    finally\n",
    "    {\n",
    "        testDataStream.Dispose();\n",
    "        if (File.Exists(tempFile))\n",
    "            File.Delete(tempFile);\n",
    "    }\n",
    "}\n",
    "\n",
    "await ProcessLargeCsvFile();\n",
    "Console.WriteLine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9282f54",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Example 2: Memory stream data processing\n",
    "var testObject = new { Name = \"John Doe\", Age = 30, City = \"New York\" };\n",
    "\n",
    "// Serialize to bytes\n",
    "var bytes = MemoryStreamProcessor.SerializeToBytes(testObject);\n",
    "Console.WriteLine($\"Serialized object to {bytes.Length} bytes\");\n",
    "\n",
    "// Deserialize back\n",
    "var deserializedObject = MemoryStreamProcessor.DeserializeFromBytes<object>(bytes);\n",
    "Console.WriteLine($\"Deserialized object: {deserializedObject}\");\n",
    "Console.WriteLine();\n",
    "\n",
    "// Example 3: Stream-based data transformation\n",
    "var numbers = Enumerable.Range(1, 100);\n",
    "var processedNumbers = await MemoryStreamProcessor.ProcessDataInChunksAsync(\n",
    "    numbers,\n",
    "    async chunk => \n",
    "    {\n",
    "        // Simulate some async processing\n",
    "        await Task.Delay(10);\n",
    "        return chunk.Where(n => n % 2 == 0).Select(n => n * 2).ToList();\n",
    "    },\n",
    "    chunkSize: 20\n",
    ");\n",
    "\n",
    "Console.WriteLine($\"Processed {processedNumbers.Count} even numbers (doubled): [{string.Join(\", \", processedNumbers.Take(10))}...]\");\n",
    "Console.WriteLine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e28b50",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Example 4: Compression with streams\n",
    "var testContent = \"This is a test content that will be compressed using GZIP. \" +\n",
    "                 \"Streams allow us to handle compression efficiently without loading \" +\n",
    "                 \"all data into memory at once. This is especially useful for large files.\";\n",
    "\n",
    "var tempGzipFile = Path.ChangeExtension(Path.GetTempFileName(), \".gz\");\n",
    "\n",
    "try\n",
    "{\n",
    "    // Compress data\n",
    "    await CompressionProcessor.WriteGzipFileAsync(tempGzipFile, testContent);\n",
    "    \n",
    "    var originalSize = System.Text.Encoding.UTF8.GetBytes(testContent).Length;\n",
    "    var compressedSize = new FileInfo(tempGzipFile).Length;\n",
    "    \n",
    "    Console.WriteLine($\"Original size: {originalSize} bytes\");\n",
    "    Console.WriteLine($\"Compressed size: {compressedSize} bytes\");\n",
    "    Console.WriteLine($\"Compression ratio: {(double)compressedSize / originalSize:P1}\");\n",
    "    \n",
    "    // Decompress data\n",
    "    var decompressedContent = await CompressionProcessor.ReadGzipFileAsync(tempGzipFile);\n",
    "    Console.WriteLine($\"Content matches: {testContent == decompressedContent}\");\n",
    "    Console.WriteLine($\"Decompressed content preview: {decompressedContent.Substring(0, 50)}...\");\n",
    "}\n",
    "finally\n",
    "{\n",
    "    if (File.Exists(tempGzipFile))\n",
    "        File.Delete(tempGzipFile);\n",
    "}\n",
    "Console.WriteLine();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba90ae8",
   "metadata": {},
   "source": [
    "### ❌ Bad Examples - Poor Stream Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a7f69",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// ❌ BAD: Not using 'using' statements - resource leaks\n",
    "public class BadFileReader\n",
    "{\n",
    "    // ❌ BAD: Resources not properly disposed\n",
    "    public static string ReadFileBadly(string filePath)\n",
    "    {\n",
    "        var fileStream = new FileStream(filePath, FileMode.Open); // Not disposed!\n",
    "        var reader = new StreamReader(fileStream); // Not disposed!\n",
    "        \n",
    "        return reader.ReadToEnd(); // Resources leaked if exception occurs\n",
    "    }\n",
    "    \n",
    "    // ❌ BAD: Manual disposal without exception handling\n",
    "    public static string ReadFileManualDisposal(string filePath)\n",
    "    {\n",
    "        FileStream fileStream = null;\n",
    "        StreamReader reader = null;\n",
    "        \n",
    "        try\n",
    "        {\n",
    "            fileStream = new FileStream(filePath, FileMode.Open);\n",
    "            reader = new StreamReader(fileStream);\n",
    "            \n",
    "            return reader.ReadToEnd();\n",
    "        }\n",
    "        finally\n",
    "        {\n",
    "            reader?.Dispose(); // What if reader creation failed?\n",
    "            fileStream?.Dispose(); // Verbose and error-prone\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // ❌ BAD: Using File.ReadAllText when streams are required\n",
    "    public static string ReadFileSimple(string filePath)\n",
    "    {\n",
    "        // While this works, it doesn't demonstrate stream usage\n",
    "        // and loads entire file into memory\n",
    "        return File.ReadAllText(filePath);\n",
    "    }\n",
    "    \n",
    "    // ❌ BAD: Synchronous operations in async context\n",
    "    public static async Task<string> ReadFileAsyncBadly(string filePath)\n",
    "    {\n",
    "        // Using sync methods in async method defeats the purpose\n",
    "        using var stream = new FileStream(filePath, FileMode.Open);\n",
    "        using var reader = new StreamReader(stream);\n",
    "        \n",
    "        return reader.ReadToEnd(); // Should be ReadToEndAsync()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64421ac4",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// ❌ BAD: Poor HTTP stream handling\n",
    "public class BadHttpLoader\n",
    "{\n",
    "    // ❌ BAD: Not disposing HttpClient (though in real apps, reuse HttpClient)\n",
    "    public static async Task<string> DownloadBadly(string url)\n",
    "    {\n",
    "        var client = new HttpClient(); // Not disposed - socket exhaustion!\n",
    "        var response = await client.GetAsync(url); // Not disposed!\n",
    "        \n",
    "        return await response.Content.ReadAsStringAsync();\n",
    "    }\n",
    "    \n",
    "    // ❌ BAD: Loading entire response into memory\n",
    "    public static async Task DownloadLargeFileBadly(string url, string filePath)\n",
    "    {\n",
    "        using var client = new HttpClient();\n",
    "        \n",
    "        // This loads entire file into memory first!\n",
    "        var data = await client.GetByteArrayAsync(url);\n",
    "        \n",
    "        await File.WriteAllBytesAsync(filePath, data);\n",
    "    }\n",
    "    \n",
    "    // ❌ BAD: No error handling or timeout\n",
    "    public static async Task<string> DownloadWithoutErrorHandling(string url)\n",
    "    {\n",
    "        using var client = new HttpClient();\n",
    "        // No timeout, no error handling, no validation\n",
    "        var response = await client.GetStringAsync(url);\n",
    "        return response;\n",
    "    }\n",
    "    \n",
    "    // ❌ BAD: Blocking async operations\n",
    "    public static string DownloadBlocking(string url)\n",
    "    {\n",
    "        using var client = new HttpClient();\n",
    "        \n",
    "        // Using .Result can cause deadlocks\n",
    "        return client.GetStringAsync(url).Result;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f22ef8",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// ❌ BAD: Inefficient memory usage\n",
    "public class BadMemoryUsage\n",
    "{\n",
    "    // ❌ BAD: Loading entire large file into string\n",
    "    public static List<string> ProcessLargeFileInefficiently(string filePath)\n",
    "    {\n",
    "        // This loads entire file into memory at once\n",
    "        var content = File.ReadAllText(filePath);\n",
    "        var lines = content.Split('\\n');\n",
    "        \n",
    "        // Then processes it - memory usage is doubled!\n",
    "        return lines.Where(line => !string.IsNullOrWhiteSpace(line))\n",
    "                   .Select(line => line.Trim())\n",
    "                   .ToList();\n",
    "    }\n",
    "    \n",
    "    // ❌ BAD: Creating unnecessary byte arrays\n",
    "    public static async Task CopyFileInefficiently(string source, string destination)\n",
    "    {\n",
    "        // Loads entire file into memory\n",
    "        var data = await File.ReadAllBytesAsync(source);\n",
    "        await File.WriteAllBytesAsync(destination, data);\n",
    "        \n",
    "        // For large files, this wastes memory and can cause OutOfMemoryException\n",
    "    }\n",
    "    \n",
    "    // ❌ BAD: Not using buffering\n",
    "    public static async Task CopyFileByteByByte(string source, string destination)\n",
    "    {\n",
    "        using var sourceStream = new FileStream(source, FileMode.Open);\n",
    "        using var destStream = new FileStream(destination, FileMode.Create);\n",
    "        \n",
    "        int byteValue;\n",
    "        // Extremely inefficient - one byte at a time!\n",
    "        while ((byteValue = sourceStream.ReadByte()) != -1)\n",
    "        {\n",
    "            destStream.WriteByte((byte)byteValue);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // ❌ BAD: String concatenation in loops\n",
    "    public static string ProcessTextFileInefficiently(string filePath)\n",
    "    {\n",
    "        using var stream = new FileStream(filePath, FileMode.Open);\n",
    "        using var reader = new StreamReader(stream);\n",
    "        \n",
    "        string result = \"\";\n",
    "        string line;\n",
    "        \n",
    "        // String concatenation creates new string objects each time\n",
    "        while ((line = reader.ReadLine()) != null)\n",
    "        {\n",
    "            result += line.ToUpper() + \"\\n\"; // Very inefficient!\n",
    "        }\n",
    "        \n",
    "        return result;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f3c759",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// ❌ BAD USAGE: Demonstrate the problems with poor stream usage\n",
    "\n",
    "// These examples show what NOT to do:\n",
    "Console.WriteLine(\"❌ Examples of what NOT to do:\");\n",
    "Console.WriteLine(\"1. Not using 'using' statements - causes resource leaks\");\n",
    "Console.WriteLine(\"2. Loading entire large files into memory - causes OutOfMemoryException\");\n",
    "Console.WriteLine(\"3. Using synchronous methods in async contexts - blocks threads\");\n",
    "Console.WriteLine(\"4. Reading/writing byte by byte - extremely slow\");\n",
    "Console.WriteLine(\"5. String concatenation in loops - creates many temporary objects\");\n",
    "Console.WriteLine(\"6. Not disposing HttpClient properly - socket exhaustion\");\n",
    "Console.WriteLine(\"7. Using .Result on async operations - can cause deadlocks\");\n",
    "Console.WriteLine(\"8. No error handling or timeouts - unreliable operations\");\n",
    "Console.WriteLine();\n",
    "\n",
    "// Show memory efficiency difference\n",
    "Console.WriteLine(\"Memory usage comparison:\");\n",
    "Console.WriteLine(\"✅ Stream-based: Constant memory usage regardless of file size\");\n",
    "Console.WriteLine(\"❌ File.ReadAllText: Memory usage = file size (+ processing overhead)\");\n",
    "Console.WriteLine(\"❌ Byte-by-byte: Constant memory but extremely slow (system call per byte)\");\n",
    "Console.WriteLine();\n",
    "\n",
    "// Performance implications\n",
    "Console.WriteLine(\"Performance implications:\");\n",
    "Console.WriteLine(\"✅ Async streams: Non-blocking, scalable\");\n",
    "Console.WriteLine(\"✅ Buffered operations: Efficient I/O\");\n",
    "Console.WriteLine(\"❌ Sync in async: Thread pool starvation\");\n",
    "Console.WriteLine(\"❌ No buffering: Many system calls\");\n",
    "Console.WriteLine(\"❌ Resource leaks: Memory and handle exhaustion\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a247a428",
   "metadata": {},
   "source": [
    "## Domain-Specific Stream Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2c2e6",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// ✅ GOOD: Real-world application scenarios\n",
    "public class LogFileProcessor\n",
    "{\n",
    "    // Process log files that might be very large\n",
    "    public static async IAsyncEnumerable<LogEntry> ReadLogEntriesAsync(string logFilePath)\n",
    "    {\n",
    "        using var fileStream = new FileStream(logFilePath, FileMode.Open, FileAccess.Read);\n",
    "        using var reader = new StreamReader(fileStream);\n",
    "        \n",
    "        string line;\n",
    "        while ((line = await reader.ReadLineAsync()) != null)\n",
    "        {\n",
    "            if (TryParseLogEntry(line, out var logEntry))\n",
    "            {\n",
    "                yield return logEntry;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    private static bool TryParseLogEntry(string line, out LogEntry logEntry)\n",
    "    {\n",
    "        logEntry = null;\n",
    "        \n",
    "        if (string.IsNullOrWhiteSpace(line))\n",
    "            return false;\n",
    "            \n",
    "        var parts = line.Split(' ', 4);\n",
    "        if (parts.Length < 4)\n",
    "            return false;\n",
    "            \n",
    "        if (DateTime.TryParse($\"{parts[0]} {parts[1]}\", out var timestamp))\n",
    "        {\n",
    "            logEntry = new LogEntry\n",
    "            {\n",
    "                Timestamp = timestamp,\n",
    "                Level = parts[2],\n",
    "                Message = parts[3]\n",
    "            };\n",
    "            return true;\n",
    "        }\n",
    "        \n",
    "        return false;\n",
    "    }\n",
    "    \n",
    "    // Write filtered logs to new file\n",
    "    public static async Task FilterLogsAsync(string inputPath, string outputPath, \n",
    "                                           string minLevel = \"ERROR\")\n",
    "    {\n",
    "        var levelPriority = new Dictionary<string, int>\n",
    "        {\n",
    "            [\"DEBUG\"] = 1,\n",
    "            [\"INFO\"] = 2,\n",
    "            [\"WARN\"] = 3,\n",
    "            [\"ERROR\"] = 4,\n",
    "            [\"FATAL\"] = 5\n",
    "        };\n",
    "        \n",
    "        var minPriority = levelPriority.GetValueOrDefault(minLevel, 4);\n",
    "        \n",
    "        using var outputStream = new FileStream(outputPath, FileMode.Create, FileAccess.Write);\n",
    "        using var writer = new StreamWriter(outputStream);\n",
    "        \n",
    "        await foreach (var logEntry in ReadLogEntriesAsync(inputPath))\n",
    "        {\n",
    "            var entryPriority = levelPriority.GetValueOrDefault(logEntry.Level, 0);\n",
    "            if (entryPriority >= minPriority)\n",
    "            {\n",
    "                await writer.WriteLineAsync($\"{logEntry.Timestamp:yyyy-MM-dd HH:mm:ss} {logEntry.Level} {logEntry.Message}\");\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "public class LogEntry\n",
    "{\n",
    "    public DateTime Timestamp { get; set; }\n",
    "    public string Level { get; set; }\n",
    "    public string Message { get; set; }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6289de",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// ✅ GOOD: Configuration file processing\n",
    "public class ConfigurationProcessor\n",
    "{\n",
    "    // Read configuration with stream validation\n",
    "    public static async Task<Dictionary<string, string>> LoadConfigAsync(string configPath)\n",
    "    {\n",
    "        var config = new Dictionary<string, string>();\n",
    "        \n",
    "        if (!File.Exists(configPath))\n",
    "            return config;\n",
    "            \n",
    "        using var fileStream = new FileStream(configPath, FileMode.Open, FileAccess.Read);\n",
    "        using var reader = new StreamReader(fileStream);\n",
    "        \n",
    "        string line;\n",
    "        int lineNumber = 0;\n",
    "        \n",
    "        while ((line = await reader.ReadLineAsync()) != null)\n",
    "        {\n",
    "            lineNumber++;\n",
    "            \n",
    "            // Skip comments and empty lines\n",
    "            line = line.Trim();\n",
    "            if (string.IsNullOrEmpty(line) || line.StartsWith(\"#\"))\n",
    "                continue;\n",
    "                \n",
    "            var equalIndex = line.IndexOf('=');\n",
    "            if (equalIndex > 0)\n",
    "            {\n",
    "                var key = line.Substring(0, equalIndex).Trim();\n",
    "                var value = line.Substring(equalIndex + 1).Trim();\n",
    "                \n",
    "                if (!string.IsNullOrEmpty(key))\n",
    "                {\n",
    "                    config[key] = value;\n",
    "                }\n",
    "            }\n",
    "            else\n",
    "            {\n",
    "                Console.WriteLine($\"Warning: Invalid config line {lineNumber}: {line}\");\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return config;\n",
    "    }\n",
    "    \n",
    "    // Write configuration with backup\n",
    "    public static async Task SaveConfigAsync(string configPath, Dictionary<string, string> config)\n",
    "    {\n",
    "        // Create backup if file exists\n",
    "        if (File.Exists(configPath))\n",
    "        {\n",
    "            var backupPath = $\"{configPath}.backup\";\n",
    "            await CopyFileWithStreamAsync(configPath, backupPath);\n",
    "        }\n",
    "        \n",
    "        using var fileStream = new FileStream(configPath, FileMode.Create, FileAccess.Write);\n",
    "        using var writer = new StreamWriter(fileStream);\n",
    "        \n",
    "        await writer.WriteLineAsync($\"# Configuration file generated on {DateTime.Now:yyyy-MM-dd HH:mm:ss}\");\n",
    "        await writer.WriteLineAsync();\n",
    "        \n",
    "        foreach (var kvp in config.OrderBy(x => x.Key))\n",
    "        {\n",
    "            await writer.WriteLineAsync($\"{kvp.Key}={kvp.Value}\");\n",
    "        }\n",
    "        \n",
    "        await writer.FlushAsync();\n",
    "    }\n",
    "    \n",
    "    private static async Task CopyFileWithStreamAsync(string source, string destination)\n",
    "    {\n",
    "        using var sourceStream = new FileStream(source, FileMode.Open, FileAccess.Read);\n",
    "        using var destStream = new FileStream(destination, FileMode.Create, FileAccess.Write);\n",
    "        \n",
    "        await sourceStream.CopyToAsync(destStream);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a0492",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Usage examples for domain-specific stream processing\n",
    "\n",
    "// Example 1: Create and process a sample log file\n",
    "var tempLogFile = Path.GetTempFileName();\n",
    "var filteredLogFile = Path.ChangeExtension(tempLogFile, \".filtered.log\");\n",
    "\n",
    "try\n",
    "{\n",
    "    // Create sample log data\n",
    "    var sampleLogs = new[]\n",
    "    {\n",
    "        $\"{DateTime.Now.AddHours(-3):yyyy-MM-dd HH:mm:ss} INFO Application started\",\n",
    "        $\"{DateTime.Now.AddHours(-2):yyyy-MM-dd HH:mm:ss} DEBUG User login attempt\",\n",
    "        $\"{DateTime.Now.AddHours(-1):yyyy-MM-dd HH:mm:ss} WARN Invalid password attempt\",\n",
    "        $\"{DateTime.Now.AddMinutes(-30):yyyy-MM-dd HH:mm:ss} ERROR Database connection failed\",\n",
    "        $\"{DateTime.Now.AddMinutes(-15):yyyy-MM-dd HH:mm:ss} FATAL System crash detected\",\n",
    "        $\"{DateTime.Now:yyyy-MM-dd HH:mm:ss} INFO System recovered\"\n",
    "    };\n",
    "    \n",
    "    await File.WriteAllLinesAsync(tempLogFile, sampleLogs);\n",
    "    \n",
    "    Console.WriteLine(\"Sample log entries:\");\n",
    "    await foreach (var logEntry in LogFileProcessor.ReadLogEntriesAsync(tempLogFile))\n",
    "    {\n",
    "        Console.WriteLine($\"{logEntry.Timestamp:HH:mm:ss} [{logEntry.Level}] {logEntry.Message}\");\n",
    "    }\n",
    "    \n",
    "    // Filter to only ERROR and FATAL messages\n",
    "    await LogFileProcessor.FilterLogsAsync(tempLogFile, filteredLogFile, \"ERROR\");\n",
    "    \n",
    "    Console.WriteLine(\"\\nFiltered log entries (ERROR and above):\");\n",
    "    var filteredContent = await File.ReadAllTextAsync(filteredLogFile);\n",
    "    Console.WriteLine(filteredContent);\n",
    "}\n",
    "finally\n",
    "{\n",
    "    File.Delete(tempLogFile);\n",
    "    File.Delete(filteredLogFile);\n",
    "}\n",
    "Console.WriteLine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a0fd4",
   "metadata": {
    "vscode": {
     "languageId": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Example 2: Configuration file processing\n",
    "var tempConfigFile = Path.ChangeExtension(Path.GetTempFileName(), \".config\");\n",
    "\n",
    "try\n",
    "{\n",
    "    // Create sample configuration\n",
    "    var config = new Dictionary<string, string>\n",
    "    {\n",
    "        [\"database.host\"] = \"localhost\",\n",
    "        [\"database.port\"] = \"5432\",\n",
    "        [\"database.name\"] = \"myapp\",\n",
    "        [\"app.debug\"] = \"true\",\n",
    "        [\"app.timeout\"] = \"30\",\n",
    "        [\"logging.level\"] = \"INFO\"\n",
    "    };\n",
    "    \n",
    "    // Save configuration\n",
    "    await ConfigurationProcessor.SaveConfigAsync(tempConfigFile, config);\n",
    "    \n",
    "    Console.WriteLine(\"Saved configuration file:\");\n",
    "    var savedContent = await File.ReadAllTextAsync(tempConfigFile);\n",
    "    Console.WriteLine(savedContent);\n",
    "    \n",
    "    // Load configuration back\n",
    "    var loadedConfig = await ConfigurationProcessor.LoadConfigAsync(tempConfigFile);\n",
    "    \n",
    "    Console.WriteLine(\"Loaded configuration:\");\n",
    "    foreach (var kvp in loadedConfig)\n",
    "    {\n",
    "        Console.WriteLine($\"{kvp.Key} = {kvp.Value}\");\n",
    "    }\n",
    "    \n",
    "    Console.WriteLine($\"\\nConfiguration entries loaded: {loadedConfig.Count}\");\n",
    "}\n",
    "finally\n",
    "{\n",
    "    File.Delete(tempConfigFile);\n",
    "    var backupFile = tempConfigFile + \".backup\";\n",
    "    if (File.Exists(backupFile))\n",
    "        File.Delete(backupFile);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d247762",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What Makes Stream Usage \"Meaningful\":\n",
    "\n",
    "**Perfect Use Cases:**\n",
    "- **Large files** - Process without loading everything into memory\n",
    "- **Network operations** - Download/upload with progress and efficiency\n",
    "- **Data transformation** - Process data as it flows through\n",
    "- **Compression** - Handle compressed data efficiently\n",
    "- **Real-time processing** - Log files, streaming data\n",
    "- **Resource management** - Proper disposal with `using` statements\n",
    "\n",
    "**Key Benefits:**\n",
    "1. **Memory efficiency** - Constant memory usage regardless of data size\n",
    "2. **Performance** - Async operations don't block threads\n",
    "3. **Resource safety** - Automatic disposal prevents leaks\n",
    "4. **Scalability** - Handle large datasets without memory constraints\n",
    "5. **Flexibility** - Same interface for files, network, memory, compression\n",
    "\n",
    "### When Streams Add Real Value:\n",
    "\n",
    "**File Operations:**\n",
    "- Large file processing: log analysis, data imports\n",
    "- Real-time file monitoring: tail -f equivalent\n",
    "- File transformations: encoding, formatting\n",
    "\n",
    "**Network Operations:**\n",
    "- Large file downloads with progress\n",
    "- Streaming API responses\n",
    "- Real-time data feeds\n",
    "\n",
    "**Data Processing:**\n",
    "- CSV/JSON processing without memory limits\n",
    "- Data compression/decompression\n",
    "- Encryption/decryption pipelines\n",
    "\n",
    "### Red Flags (Avoid These):\n",
    "\n",
    "**Don't Use Streams When:**\n",
    "- **Small files** - `File.ReadAllText()` is simpler for small files\n",
    "- **Simple operations** - One-time reads of config files\n",
    "- **Memory isn't a concern** - Processing small datasets\n",
    "\n",
    "**Anti-Patterns:**\n",
    "- Not using `using` statements - causes resource leaks\n",
    "- Loading entire streams into memory - defeats the purpose\n",
    "- Synchronous operations in async contexts - blocks threads\n",
    "- Reading/writing byte by byte - extremely inefficient\n",
    "- Ignoring error handling - unreliable operations\n",
    "- Using `.Result` on async operations - can cause deadlocks\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Always use `using` statements** - Ensures proper resource disposal\n",
    "2. **Prefer async operations** - Don't block threads unnecessarily\n",
    "3. **Use appropriate buffer sizes** - Balance memory usage and performance\n",
    "4. **Handle errors gracefully** - Network and file operations can fail\n",
    "5. **Consider progress reporting** - For long-running operations\n",
    "6. **Choose the right stream type** - File, Memory, Network, Compression\n",
    "7. **Validate inputs** - Check file existence, URL validity, etc.\n",
    "8. **Consider cancellation** - Support for cancellation tokens\n",
    "\n",
    "### Examples Summary:\n",
    "\n",
    "**✅ Good Examples Shown:**\n",
    "- File operations: CSV processing, large file copying, line-by-line reading\n",
    "- HTTP operations: Large file downloads, JSON streaming, upload operations\n",
    "- Memory streams: Data serialization, chunk processing, test data generation\n",
    "- Compression: GZIP files, ZIP archives, data compression pipelines\n",
    "- Domain-specific: Log file processing, configuration management\n",
    "- Resource management: Proper `using` statements, async patterns\n",
    "\n",
    "**❌ Bad Examples Highlighted:**\n",
    "- Resource leaks: Not disposing streams properly\n",
    "- Memory inefficiency: Loading entire files unnecessarily\n",
    "- Performance issues: Sync operations in async contexts\n",
    "- Poor error handling: No validation or timeout handling\n",
    "- Blocking operations: Using `.Result` on async calls\n",
    "\n",
    "These examples demonstrate how streams enable efficient, scalable, and safe data processing when used appropriately. The key is understanding when the benefits of streams (memory efficiency, resource management, async support) outweigh the simplicity of basic file operations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
